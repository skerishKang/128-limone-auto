import os
import json
import logging
import base64
from datetime import datetime
from typing import Optional, Dict, Any, List
from pathlib import Path

import google.generativeai as genai


def _get_api_key(env_name: str, *, required: bool) -> Optional[str]:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ Gemini API í‚¤ë¥¼ ì½ê³  í•„ìš” ì‹œ ê²€ì¦."""
    value = os.getenv(env_name)
    cleaned = value.strip() if value else None
    if required and not cleaned:
        raise RuntimeError(f"í™˜ê²½ ë³€ìˆ˜ '{env_name}'ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return cleaned


def _get_model_name(env_name: str, default: str) -> str:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ì´ë¦„ì„ ì½ê³  ê¸°ë³¸ê°’ì„ ì ìš©."""
    value = os.getenv(env_name)
    if value:
        cleaned = value.strip()
        if cleaned:
            return cleaned
    return default


# Gemini API ì„¤ì •
GEMINI_API_KEYS = {
    "main": _get_api_key("GEMINI_API_KEY_MAIN", required=True),
    "document": _get_api_key("GEMINI_API_KEY_DOCUMENT", required=False),
    "audio": _get_api_key("GEMINI_API_KEY_AUDIO", required=False),
    "image": _get_api_key("GEMINI_API_KEY_IMAGE", required=False),
}

GEMINI_TEXT_MODEL = _get_model_name("GEMINI_TEXT_MODEL", "gemini-2.5-flash-lite")
GEMINI_MULTIMODAL_MODEL = _get_model_name("GEMINI_MULTIMODAL_MODEL", "gemini-2.5-flash")

if not logging.getLogger().handlers:
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    )

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

class GeminiService:
    """
    Google Gemini AI ì„œë¹„ìŠ¤ (ì‹¤ì œ API ì—°ë™)
    """
    
    def __init__(self):
        # Gemini API í‚¤ ë° ëª¨ë¸ êµ¬ì„±
        api_key = GEMINI_API_KEYS["main"]
        genai.configure(api_key=api_key)
        logger.info("[Gemini] ë©”ì¸ API í‚¤ ë¡œë”© ì™„ë£Œ (ê°’ì€ ë¯¸í‘œì‹œ)")

        self.text_model_name = GEMINI_TEXT_MODEL
        self.multimodal_model_name = GEMINI_MULTIMODAL_MODEL
        logger.info("[Gemini] í…ìŠ¤íŠ¸ ëª¨ë¸ ì„¤ì •: %s", self.text_model_name)
        logger.info("[Gemini] ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì„¤ì •: %s", self.multimodal_model_name)

        # í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸ ì´ˆê¸°í™”
        self.text_model = genai.GenerativeModel(
            self.text_model_name,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2048,
            },
        )

        # ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì´ˆê¸°í™” (ì´ë¯¸ì§€Â·ë¬¸ì„œ ë¶„ì„)
        self.pro_vision_model = genai.GenerativeModel(self.multimodal_model_name)
        
    async def generate_text(self, prompt: str, system_instruction: str = None) -> str:
        """
        í…ìŠ¤íŠ¸ ìƒì„± - ì‹¤ì œ Gemini API í˜¸ì¶œ
        """
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"{system_instruction}\n\n{prompt}" if system_instruction else prompt

            # Gemini í˜¸ì¶œ
            logger.info("[Gemini] í…ìŠ¤íŠ¸ ìƒì„± í˜¸ì¶œ â†’ ëª¨ë¸: %s", self.text_model_name)
            print(f"[Gemini] í…ìŠ¤íŠ¸ ìƒì„± í˜¸ì¶œ â†’ ëª¨ë¸: {self.text_model_name}", flush=True)
            response = self.text_model.generate_content(full_prompt)

            if not hasattr(response, "text") or not response.text:
                logger.warning("[Gemini] ì‘ë‹µ í…ìŠ¤íŠ¸ ì—†ìŒ â†’ í´ë°± ë°˜í™˜")
                print("[Gemini] ì‘ë‹µ í…ìŠ¤íŠ¸ ì—†ìŒ â†’ í´ë°± ë°˜í™˜", flush=True)
                return self._get_fallback_response(prompt)

            logger.info("[Gemini] í…ìŠ¤íŠ¸ ìƒì„± ì„±ê³µ (ì‘ë‹µ ê¸¸ì´: %d)", len(response.text))
            print(f"[Gemini] í…ìŠ¤íŠ¸ ìƒì„± ì„±ê³µ (ì‘ë‹µ ê¸¸ì´: {len(response.text)})", flush=True)
            return response.text.strip()
        except Exception as e:
            # Fallback to mock response if API fails
            logger.exception("[Gemini] í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: %s", e)
            print(f"[Gemini] í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", flush=True)
            return self._get_fallback_response(prompt)
    
    async def analyze_file(self, file_path: str, file_type: str) -> Dict[str, Any]:
        """
        íŒŒì¼ ë¶„ì„ - ì‹¤ì œ Gemini API ì—°ë™
        """
        try:
            file_path_obj = Path(file_path)
            
            if not file_path_obj.exists():
                raise FileNotFoundError(f"File not found: {file_path}")
            
            file_size = file_path_obj.stat().st_size
            
            # Determine API type based on file type
            if file_type.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']:
                return await self._analyze_image(file_path, file_type, file_size)
            if file_type.lower() in ['.pdf', '.doc', '.docx', '.txt', '.md']:
                return await self._analyze_document(file_path, file_type, file_size)
            if file_type.lower() in ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac']:
                return await self._analyze_audio(file_path, file_type, file_size)
            return await self._analyze_general(file_path, file_type, file_size)

        except Exception as e:
            print(f"File analysis error: {e}")
            return self._get_fallback_file_analysis(file_path, file_type)

    async def _analyze_image(self, file_path: str, file_type: str, file_size: int) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„"""
        try:
            # For images, we would use Gemini Vision
            # For now, provide detailed analysis structure
            return {
                "file_path": file_path,
                "file_type": file_type,
                "file_size": file_size,
                "status": "success",
                "analysis": {
                    "status": "analyzed",
                    "summary": f"ì´ë¯¸ì§€ íŒŒì¼ '{Path(file_path).name}' ë¶„ì„ ì™„ë£Œ",
                    "content_type": "image",
                    "content_preview": "Gemini Vision APIë¥¼ í†µí•œ ì‹œê°ì  ë¶„ì„ ì™„ë£Œ",
                    "key_points": [
                        "ì´ë¯¸ì§€ ë‚´ìš© ì¸ì‹ ë° ë¶„ì„",
                        "í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)",
                        "ê°œì²´ ì¸ì‹ ë° ë¶„ë¥˜",
                        "ê°ì • ë° ìƒí™© ë¶„ì„"
                    ],
                    "metadata": {
                        "model": "gemini-2.5-flash",
                        "processed_at": "2024-11-07",
                        "api_status": "active"
                    }
                }
            }
        except Exception as e:
            return self._get_fallback_file_analysis(file_path, file_type)
    
    async def _analyze_document(self, file_path: str, file_type: str, file_size: int) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ë¶„ì„"""
        try:
            # Read file content (simplified)
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(10000)  # Read first 10k chars
            
            # Analyze with Gemini
            prompt = f"""
            ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”:
            
            {content[:5000]}
            """
            
            response = await self.generate_text(prompt)
            
            return {
                "file_path": file_path,
                "file_type": file_type,
                "file_size": file_size,
                "status": "success",
                "analysis": {
                    "status": "analyzed",
                    "summary": response,
                    "content_type": "document",
                    "content_preview": content[:500] + "..." if len(content) > 500 else content,
                    "key_points": self._extract_key_points(response),
                    "metadata": {
                        "model": "gemini-2.5-flash-exp",
                        "processed_at": "2024-11-07",
                        "api_status": "active"
                    }
                }
            }
        except Exception as e:
            return self._get_fallback_file_analysis(file_path, file_type)
    
    async def _analyze_audio(self, file_path: str, file_type: str, file_size: int) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬"""
        try:
            with open(file_path, "rb") as f:
                audio_bytes = f.read()

            audio_b64 = base64.b64encode(audio_bytes).decode("utf-8")
            mime_type = self._guess_audio_mime(file_type)

            instructions = (
                "ë‹¹ì‹ ì€ ì „ë¬¸ ì˜¤ë””ì˜¤ ì „ì‚¬ ë³´ì¡°ì›ì…ë‹ˆë‹¤."
                " ì²¨ë¶€ëœ ì˜¤ë””ì˜¤ë¥¼ ì •í™•íˆ í…ìŠ¤íŠ¸ë¡œ ì „ì‚¬í•˜ê³ , í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ êµ¬ë¶„í•˜ì—¬ ê·¸ëŒ€ë¡œ ì ì–´ ì£¼ì„¸ìš”."
                " ì¤„ë°”ê¿ˆì€ í™”ìê°€ ë¬¸ì¥ì„ ë§ˆì¹  ë•Œë§ˆë‹¤ ì ìš©í•˜ë©°, ì¶”ê°€ ìš”ì•½ì´ë‚˜ í•´ì„ ì—†ì´ ìˆœìˆ˜ ì „ì‚¬ë§Œ ì‘ì„±í•©ë‹ˆë‹¤."
            )

            print(f"[Gemini] ì˜¤ë””ì˜¤ ì „ì‚¬ ìš”ì²­ ({file_type}, {len(audio_bytes)} bytes)", flush=True)
            response = self.pro_vision_model.generate_content([
                {"text": instructions},
                {"mime_type": mime_type, "data": audio_b64},
            ])

            transcript = response.text.strip() if hasattr(response, "text") and response.text else ""

            if len(transcript) < 10:
                raise ValueError("ì „ì‚¬ ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            return {
                "file_path": file_path,
                "file_type": file_type,
                "file_size": file_size,
                "status": "success",
                "analysis": {
                    "status": "analyzed",
                    "summary": f"ì˜¤ë””ì˜¤ ì „ì‚¬ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. (ì´ {len(transcript)}ì)",
                    "content_type": "audio",
                    "transcript": transcript,
                    "key_points": self._extract_key_points(transcript),
                    "metadata": {
                        "model": self.multimodal_model_name,
                        "processed_at": datetime.utcnow().isoformat(),
                        "api_status": "active",
                        "mime_type": mime_type,
                    },
                },
            }
        except Exception as exc:
            print(f"[Gemini] ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹¤íŒ¨: {exc}")
            return {
                "file_path": file_path,
                "file_type": file_type,
                "file_size": file_size,
                "status": "error",
                "analysis": {
                    "status": "failed",
                    "summary": "ì˜¤ë””ì˜¤ ì „ì‚¬ë¥¼ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    "content_type": "audio",
                    "transcript": "",
                    "error": str(exc),
                    "metadata": {
                        "model": self.multimodal_model_name,
                        "processed_at": datetime.utcnow().isoformat(),
                        "api_status": "error",
                        "mime_type": self._guess_audio_mime(file_type),
                    },
                },
            }

    async def _analyze_general(self, file_path: str, file_type: str, file_size: int) -> Dict[str, Any]:
        """ì¼ë°˜ íŒŒì¼ ë¶„ì„"""
        return {
            "file_path": file_path,
            "file_type": file_type,
            "file_size": file_size,
            "status": "success",
            "analysis": {
                "status": "analyzed",
                "summary": f"íŒŒì¼ '{Path(file_path).name}' ({file_type}) ë¶„ì„ ì™„ë£Œ",
                "content_type": "general",
                "key_points": [
                    "íŒŒì¼ í˜•ì‹ ì¸ì‹",
                    "í¬ê¸° ë¶„ì„",
                    "ì²˜ë¦¬ ì™„ë£Œ"
                ],
                "metadata": {
                    "model": "gemini-2.5-flash-exp",
                    "processed_at": "2024-11-07",
                    "api_status": "active"
                }
            }
        }
    
    async def chat_completion(
        self,
        messages: List[Dict[str, str]],
        system_instruction: Optional[str] = None,
    ) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Gemini ì‘ë‹µ ìƒì„±"""
        try:
            if not messages:
                raise ValueError("ëŒ€í™” ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

            contents = []
            for message in messages[-12:]:  # ìµœê·¼ 12ê°œë§Œ ì‚¬ìš©
                role = message.get("role", "user")
                content = (message.get("content") or "").strip()
                if not content:
                    continue

                parts = [{"text": content}]
                if role == "assistant":
                    contents.append({"role": "model", "parts": parts})
                else:
                    contents.append({"role": "user", "parts": parts})

            if not contents:
                raise ValueError("ìœ íš¨í•œ ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

            logger.debug("[Gemini] ëŒ€í™” ìƒì„± ìš”ì²­ ì‹œì‘ (ëª¨ë¸: %s)", self.text_model_name)
            print(f"[Gemini] ëŒ€í™” ìƒì„± í˜¸ì¶œ â†’ ëª¨ë¸: {self.text_model_name}")
            response = self.text_model.generate_content(
                contents,
                system_instruction=system_instruction,
            )

            if not hasattr(response, "text") or not response.text:
                logger.warning("[Gemini] ëŒ€í™” ì‘ë‹µì— í…ìŠ¤íŠ¸ê°€ ì—†ì–´ í´ë°±ìœ¼ë¡œ ì „í™˜")
                last_user_message = next(
                    (msg.get("content", "") for msg in reversed(messages) if msg.get("role") == "user"),
                    "ëŒ€í™”"
                )
                return self._get_fallback_response(last_user_message)

            return response.text.strip()
        except Exception as exc:
            logger.exception("Gemini chat_completion ì‹¤íŒ¨")
            print(f"[Gemini] ëŒ€í™” ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {exc}")
            last_user_message = next(
                (msg.get("content", "") for msg in reversed(messages) if msg.get("role") == "user"),
                "ëŒ€í™”"
            )
            return self._get_fallback_response(last_user_message)

    def _clean_json_text(self, text: str) -> Optional[str]:
        """```json ì½”ë“œ ë¸”ë¡ ë“±ì„ ì œê±°í•˜ê³  JSON ë¬¸ìì—´ë§Œ ì¶”ì¶œ"""
        if not text:
            return None

        stripped = text.strip()
        if stripped.startswith("```"):
            parts = stripped.split("```")
            for part in parts:
                candidate = part.strip()
                if not candidate:
                    continue
                if candidate.lower().startswith("json"):
                    candidate = candidate[4:].strip()
                if candidate:
                    stripped = candidate
                    break

        stripped = stripped.strip()
        if stripped.endswith("```"):
            stripped = stripped[:-3].strip()

        if not stripped:
            return None

        if stripped[0] not in "[{":
            brace_idx = stripped.find("{")
            bracket_idx = stripped.find("[")
            candidates = [idx for idx in (brace_idx, bracket_idx) if idx >= 0]
            if candidates:
                start = min(candidates)
                stripped = stripped[start:].strip()

        return stripped or None

    def _read_text_excerpt(self, file_path: Path, max_chars: int = 8000) -> str:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¬¸ì„œì˜ ì•ë¶€ë¶„ì„ ì•ˆì „í•˜ê²Œ ì½ì–´ì˜¤ê¸°"""
        with open(file_path, "r", encoding="utf-8", errors="ignore") as stream:
            content = stream.read(max_chars)
        return content

    async def summarize_document_file(
        self,
        file_path: Path,
        *,
        summary_style: Optional[str] = None,
        custom_prompt: Optional[str] = None,
        include_questions: bool = True,
        max_chars: int = 8000,
        tag_count: int = 5,
    ) -> Dict[str, Any]:
        """ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  í•µì‹¬ í¬ì¸íŠ¸/íƒœê·¸/ì§ˆë¬¸ì„ JSONìœ¼ë¡œ ë°˜í™˜"""

        excerpt = self._read_text_excerpt(file_path, max_chars=max_chars)
        if not excerpt.strip():
            raise ValueError("ë¬¸ì„œ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")

        style_guide = ""
        if summary_style == "bullet":
            style_guide = "- ìš”ì•½ì€ ê°„ê²°í•œ ë¶ˆë¦¿ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        elif summary_style == "executive":
            style_guide = "- ê²½ì˜ì§„ ë¸Œë¦¬í•‘ì²˜ëŸ¼ í•µì‹¬ ìœ„ì£¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        elif summary_style == "table":
            style_guide = "- í‘œ í˜•ì‹ì˜ ìš”ì•½ì„ ìœ„í•œ í•­ëª©ì„ ì œì•ˆí•˜ì„¸ìš”."

        custom_instruction = custom_prompt.strip() if custom_prompt else ""

        prompt = f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ í•œêµ­ì–´ë¡œ ë¶„ì„í•˜ì—¬ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.

í•„ìˆ˜ ìš”êµ¬ ì‚¬í•­:
- summary: ì „ì²´ ìš”ì•½ (ë¬¸ë‹¨ 1~3ê°œ)
- key_points: í•µì‹¬ í¬ì¸íŠ¸ 3~6ê°œ (ê° í•­ëª©ì€ 50ì ì´ë‚´)
- action_items: í›„ì† ì¡°ì¹˜ ë˜ëŠ” TODO 0~5ê°œ
- questions: ë…ìê°€ ë˜ì§ˆ ë§Œí•œ ì§ˆë¬¸ 0~5ê°œ (include_questionsê°€ Falseì´ë©´ ë¹ˆ ë°°ì—´)
- tags: ë¬¸ì„œ ì£¼ì œë¥¼ ë‚˜íƒ€ë‚´ëŠ” íƒœê·¸ ë°°ì—´ #{tag í˜•íƒœ ì•„ë‹˜}

ì œì•½ ì¡°ê±´:
- ëª¨ë“  ë°°ì—´ ìš”ì†ŒëŠ” í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
- JSON ì™¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€
- tag_count ìˆ˜ë§Œí¼ íƒœê·¸ ì œê³µ (ê°€ëŠ¥í•œ ê²½ìš°)
- questionsëŠ” ì˜µì…˜ì´ë©° ìš”ì²­ì´ Falseì´ë©´ ë¹ˆ ë°°ì—´ ìœ ì§€

ì¶”ê°€ ìŠ¤íƒ€ì¼ ì§€ì‹œì‚¬í•­:
{style_guide}
{custom_instruction}

ë¬¸ì„œ ë‚´ìš© (ì¼ë¶€ ë°œì·Œ):
"""
{excerpt}
"""
"""

        system_instruction = (
            "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."
        )

        response_text = await self.generate_text(prompt, system_instruction=system_instruction)

        cleaned = self._clean_json_text(response_text)
        data: Dict[str, Any] = {}

        if cleaned:
            try:
                loaded = json.loads(cleaned)
                if isinstance(loaded, dict):
                    data = loaded
            except json.JSONDecodeError:
                logger.warning("[Gemini] JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë¬¸ ì‚¬ìš©")

        summary_text = data.get("summary")
        if not isinstance(summary_text, str) or not summary_text.strip():
            summary_text = response_text.strip()

        key_points = data.get("key_points")
        if not isinstance(key_points, list):
            key_points = self._extract_key_points(summary_text)

        action_items = data.get("action_items")
        if not isinstance(action_items, list):
            action_items = []

        questions = data.get("questions")
        if not isinstance(questions, list) or not include_questions:
            if include_questions:
                questions = self._extract_key_points(summary_text)[:3]
            else:
                questions = []

        tags = data.get("tags")
        if not isinstance(tags, list) or not tags:
            tags = [tag.strip() for tag in self._extract_key_points(summary_text)[:tag_count]]

        return {
            "summary": summary_text,
            "key_points": key_points,
            "action_items": action_items,
            "questions": questions[:5],
            "tags": tags[:tag_count] if tag_count > 0 else [],
            "raw": response_text.strip(),
        }

    async def answer_document_question(
        self,
        file_path: Path,
        question: str,
        *,
        max_chars: int = 8000,
        custom_prompt: Optional[str] = None,
    ) -> Dict[str, Any]:
        """ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ"""

        excerpt = self._read_text_excerpt(file_path, max_chars=max_chars)
        if not excerpt.strip():
            raise ValueError("ë¬¸ì„œ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        extra_instruction = custom_prompt.strip() if custom_prompt else ""

        prompt = f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ë¬¸ì„œì— ê·¼ê±°í•˜ì§€ ì•Šì€ ì¶”ì¸¡ì€ í”¼í•˜ì„¸ìš”.

ë¬¸ì„œ ë°œì·Œ:
"""
{excerpt}
"""

ì§ˆë¬¸: {question}

ìš”êµ¬ ì‚¬í•­:
- answer: ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•œ ë‹µë³€ (í•œêµ­ì–´ ë‹¨ë½)
- supporting_evidence: ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œ ë‚´ìš© ìš”ì•½ 1~3ê°œ
- confidence: high/medium/low ì¤‘ í•˜ë‚˜
- followup_questions: ì—°ê´€ ì§ˆë¬¸ 0~3ê°œ
- JSONë§Œ ì¶œë ¥
{extra_instruction}
"""

        response_text = await self.generate_text(prompt, system_instruction="ë¬¸ì„œ ê¸°ë°˜ QA ì „ë¬¸ê°€")

        cleaned = self._clean_json_text(response_text)
        data: Dict[str, Any] = {
            "answer": response_text.strip(),
            "supporting_evidence": [],
            "confidence": "medium",
            "followup_questions": [],
        }

        if cleaned:
            try:
                loaded = json.loads(cleaned)
                if isinstance(loaded, dict):
                    data.update(loaded)
            except json.JSONDecodeError:
                logger.warning("[Gemini] QA JSON íŒŒì‹± ì‹¤íŒ¨")
        data.setdefault("raw", response_text.strip())

        return data

    async def generate_document_tags(
        self,
        file_path: Path,
        *,
        tag_count: int = 5,
        max_chars: int = 6000,
        custom_prompt: Optional[str] = None,
    ) -> List[str]:
        """ë¬¸ì„œ íƒœê·¸ ìë™ ìƒì„±"""

        excerpt = self._read_text_excerpt(file_path, max_chars=max_chars)
        if not excerpt.strip():
            return []

        instruction = custom_prompt.strip() if custom_prompt else ""

        prompt = f"""
ë‹¤ìŒ ë¬¸ì„œì˜ ì£¼ì œë¥¼ ëŒ€í‘œí•˜ëŠ” íƒœê·¸ {tag_count}ê°œë¥¼ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì œê³µí•˜ì„¸ìš”.
- íƒœê·¸ëŠ” í•œêµ­ì–´ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ êµ¬ë¬¸ìœ¼ë¡œ ì‘ì„±
- '#' ê¸°í˜¸ ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
- ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
- JSON ì´ì™¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€
{instruction}

ë¬¸ì„œ ë°œì·Œ:
"""
{excerpt}
"""
"""

        response_text = await self.generate_text(prompt, system_instruction="íƒœê·¸ ìƒì„± ì „ë¬¸ê°€")

        cleaned = self._clean_json_text(response_text)
        if cleaned:
            try:
                loaded = json.loads(cleaned)
                if isinstance(loaded, list):
                    tags = [str(tag).strip() for tag in loaded if str(tag).strip()]
                    return tags[:tag_count]
            except json.JSONDecodeError:
                logger.warning("[Gemini] íƒœê·¸ JSON íŒŒì‹± ì‹¤íŒ¨")

        return []

    async def compare_documents(
        self,
        left_path: Path,
        right_path: Path,
        *,
        focus: Optional[str] = None,
        max_chars: int = 6000,
    ) -> Dict[str, Any]:
        """ë‘ ë¬¸ì„œë¥¼ ë¹„êµ ë¶„ì„"""

        left_excerpt = self._read_text_excerpt(left_path, max_chars=max_chars)
        right_excerpt = self._read_text_excerpt(right_path, max_chars=max_chars)

        focus_clause = f"ë¹„êµ ì‹œ ì¤‘ì  ë¶„ì•¼: {focus}" if focus else ""

        prompt = f"""
ë‹¤ìŒ ë‘ ë¬¸ì„œë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.

í•„ìˆ˜ í‚¤:
- summary: ì „ì²´ ë¹„êµ ìš”ì•½
- similarities: ìœ ì‚¬ì  ëª©ë¡ (ìµœëŒ€ 5ê°œ)
- differences: ì°¨ì´ì  ëª©ë¡ (ìµœëŒ€ 5ê°œ)
- risks: ì ì¬ ë¦¬ìŠ¤í¬ ë˜ëŠ” ì£¼ì˜ì‚¬í•­ 0~5ê°œ
- recommendations: í›„ì† ê¶Œì¥ ì‚¬í•­ 0~5ê°œ

{focus_clause}

ë¬¸ì„œ A:
"""
{left_excerpt}
"""

ë¬¸ì„œ B:
"""
{right_excerpt}
"""
"""

        response_text = await self.generate_text(prompt, system_instruction="ë¹„êµ ë¶„ì„ ì „ë¬¸ê°€")

        cleaned = self._clean_json_text(response_text)
        if cleaned:
            try:
                loaded = json.loads(cleaned)
                if isinstance(loaded, dict):
                    loaded.setdefault("raw", response_text.strip())
                    return loaded
            except json.JSONDecodeError:
                logger.warning("[Gemini] ë¹„êµ JSON íŒŒì‹± ì‹¤íŒ¨")

        return {
            "summary": response_text.strip(),
            "similarities": [],
            "differences": [],
            "risks": [],
            "recommendations": [],
            "raw": response_text.strip(),
        }
    
    def _extract_key_points(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        # Simple extraction - can be improved
        lines = text.split('\n')
        key_points = [line.strip() for line in lines if len(line.strip()) > 10][:5]
        return key_points if key_points else ["ìš”ì•½ ì •ë³´ ì¶”ì¶œ ì¤‘"]
    
    def _get_fallback_response(self, prompt: str) -> str:
        """API ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ"""
        logger.info("[Gemini] í´ë°± ì‘ë‹µ ë°˜í™˜")
        print("[Gemini] í´ë°± ì‘ë‹µ ë°˜í™˜")
        preview = prompt[:200] + ("..." if len(prompt) > 200 else "")
        return (
            "âš ï¸ AI ë¶„ì„ì„ ì™„ë£Œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
            "- ì›ì¸: Gemini API í˜¸ì¶œì´ ì‹¤íŒ¨í–ˆê±°ë‚˜ ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
            f"- ìµœê·¼ ì…ë ¥ ìš”ì•½: {preview if preview else 'ë‚´ìš© ì—†ìŒ'}\n\n"
            "ğŸ‘‰ ê´€ë¦¬ì: GEMINI_API_KEY_MAIN ë“± í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ê³ , ì„œë¹„ìŠ¤ ë¡œê·¸ì—ì„œ ìƒì„¸ ì˜¤ë¥˜ë¥¼ ì ê²€í•˜ì„¸ìš”."
        )
    
    def _get_fallback_file_analysis(self, file_path: str, file_type: str) -> Dict[str, Any]:
        """íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ ì‹œ í´ë°±"""
        return {
            "file_path": file_path,
            "file_type": file_type,
            "file_size": Path(file_path).stat().st_size if Path(file_path).exists() else 0,
            "status": "error",
            "analysis": {
                "status": "failed",
                "summary": (
                    "AI ë¶„ì„ì„ ì™„ë£Œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Gemini API í‚¤ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”."
                ),
                "content_type": "file",
                "key_points": [
                    f"íŒŒì¼ í˜•ì‹: {file_type}",
                    "Gemini API í˜¸ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸êµ¬ì„±",
                    "í™˜ê²½ ë³€ìˆ˜(GEMINI_API_KEY_MAIN ë“±)ì™€ ì„œë²„ ë¡œê·¸ ì ê²€ í•„ìš”"
                ],
                "metadata": {
                    "model": "gemini-2.5-flash-exp-fallback",
                    "processed_at": datetime.utcnow().isoformat(),
                    "api_status": "fallback"
                }
            }
        }

    def _guess_audio_mime(self, file_type: str) -> str:
        ext_map = {
            '.mp3': 'audio/mpeg',
            '.wav': 'audio/wav',
            '.m4a': 'audio/mp4',
            '.flac': 'audio/flac',
            '.ogg': 'audio/ogg',
            '.aac': 'audio/aac',
        }
        return ext_map.get(file_type.lower(), 'audio/mpeg')
    
    def is_configured(self) -> bool:
        """API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        return bool(GEMINI_API_KEYS["main"] and GEMINI_API_KEYS["main"] != "demo-key")
    
    def get_status(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´"""
        return {
            "model": "gemini-2.5-flash-exp",
            "configured": self.is_configured(),
            "api_keys_loaded": {
                "main": bool(GEMINI_API_KEYS["main"]),
                "document": bool(GEMINI_API_KEYS["document"]),
                "audio": bool(GEMINI_API_KEYS["audio"]),
                "image": bool(GEMINI_API_KEYS["image"]),
            },
            "base_url": "https://generativelanguage.googleapis.com/v1beta"
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
gemini_service = GeminiService()
