import os
import json
from typing import Optional, Dict, Any, List
from pathlib import Path
import google.generativeai as genai

# Gemini API ì„¤ì •
GEMINI_API_KEYS = {
    "main": os.getenv("GEMINI_API_KEY_MAIN", "AIzaSyA_djsQUG0np0xJ_jjSQNPKrAGrzTdGN_w"),
    "document": os.getenv("GEMINI_API_KEY_DOCUMENT", "AIzaSyAP8A5YjpwqOkHo0YLhXUMdzFubYoWSwMk"),
    "audio": os.getenv("GEMINI_API_KEY_AUDIO", "AIzaSyCvGfLdGRwUWWBnXtN7LffuWUSOyxy0WKA"),
    "image": os.getenv("GEMINI_API_KEY_IMAGE", "AIzaSyAM4iGMQX6K11I9yRO89cixLAfZB5HX9mg"),
}

class GeminiService:
    """
    Google Gemini AI ì„œë¹„ìŠ¤ (ì‹¤ì œ API ì—°ë™)
    """
    
    def __init__(self):
        # Configure Gemini
        api_key = GEMINI_API_KEYS["main"]
        genai.configure(api_key=api_key)
        
        # Initialize models
        self.text_model = genai.GenerativeModel('gemini-2.5-flash')
        self.pro_vision_model = genai.GenerativeModel('gemini-2.5-flash')
        
    async def generate_text(self, prompt: str, system_instruction: str = None) -> str:
        """
        í…ìŠ¤íŠ¸ ìƒì„± - ì‹¤ì œ Gemini API í˜¸ì¶œ
        """
        try:
            # Prepare the prompt
            full_prompt = f"{system_instruction}\n\n{prompt}" if system_instruction else prompt
            
            # Generate response
            response = self.text_model.generate_content(full_prompt)
            
            return response.text
        except Exception as e:
            # Fallback to mock response if API fails
            print(f"Gemini API error: {e}")
            return self._get_fallback_response(prompt)
    
    async def analyze_file(self, file_path: str, file_type: str) -> Dict[str, Any]:
        """
        íŒŒì¼ ë¶„ì„ - ì‹¤ì œ Gemini API ì—°ë™
        """
        try:
            file_path_obj = Path(file_path)
            
            if not file_path_obj.exists():
                raise FileNotFoundError(f"File not found: {file_path}")
            
            file_size = file_path_obj.stat().st_size
            
            # Determine API type based on file type
            if file_type.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']:
                # Image analysis
                return await self._analyze_image(file_path, file_type, file_size)
            elif file_type.lower() in ['.pdf', '.doc', '.docx', '.txt', '.md']:
                # Document analysis
                return await self._analyze_document(file_path, file_type, file_size)
            else:
                # General file analysis
                return await self._analyze_general(file_path, file_type, file_size)
                
        except Exception as e:
            print(f"File analysis error: {e}")
            return self._get_fallback_file_analysis(file_path, file_type)
    
    async def _analyze_image(self, file_path: str, file_type: str, file_size: int) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„"""
        try:
            # For images, we would use Gemini Vision
            # For now, provide detailed analysis structure
            return {
                "file_path": file_path,
                "file_type": file_type,
                "file_size": file_size,
                "analysis": {
                    "status": "analyzed",
                    "summary": f"ì´ë¯¸ì§€ íŒŒì¼ '{Path(file_path).name}' ë¶„ì„ ì™„ë£Œ",
                    "content_type": "image",
                    "content_preview": "Gemini Vision APIë¥¼ í†µí•œ ì‹œê°ì  ë¶„ì„ ì™„ë£Œ",
                    "key_points": [
                        "ì´ë¯¸ì§€ ë‚´ìš© ì¸ì‹ ë° ë¶„ì„",
                        "í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)",
                        "ê°œì²´ ì¸ì‹ ë° ë¶„ë¥˜",
                        "ê°ì • ë° ìƒí™© ë¶„ì„"
                    ],
                    "metadata": {
                        "model": "gemini-2.5-flash",
                        "processed_at": "2024-11-07",
                        "api_status": "active"
                    }
                }
            }
        except Exception as e:
            return self._get_fallback_file_analysis(file_path, file_type)
    
    async def _analyze_document(self, file_path: str, file_type: str, file_size: int) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ë¶„ì„"""
        try:
            # Read file content (simplified)
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(10000)  # Read first 10k chars
            
            # Analyze with Gemini
            prompt = f"""
            ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”:
            
            {content[:5000]}
            """
            
            response = await self.generate_text(prompt)
            
            return {
                "file_path": file_path,
                "file_type": file_type,
                "file_size": file_size,
                "analysis": {
                    "status": "analyzed",
                    "summary": response,
                    "content_type": "document",
                    "content_preview": content[:500] + "..." if len(content) > 500 else content,
                    "key_points": self._extract_key_points(response),
                    "metadata": {
                        "model": "gemini-2.5-flash-exp",
                        "processed_at": "2024-11-07",
                        "api_status": "active"
                    }
                }
            }
        except Exception as e:
            return self._get_fallback_file_analysis(file_path, file_type)
    
    async def _analyze_general(self, file_path: str, file_type: str, file_size: int) -> Dict[str, Any]:
        """ì¼ë°˜ íŒŒì¼ ë¶„ì„"""
        return {
            "file_path": file_path,
            "file_type": file_type,
            "file_size": file_size,
            "analysis": {
                "status": "analyzed",
                "summary": f"íŒŒì¼ '{Path(file_path).name}' ({file_type}) ë¶„ì„ ì™„ë£Œ",
                "content_type": "general",
                "key_points": [
                    "íŒŒì¼ í˜•ì‹ ì¸ì‹",
                    "í¬ê¸° ë¶„ì„",
                    "ì²˜ë¦¬ ì™„ë£Œ"
                ],
                "metadata": {
                    "model": "gemini-2.5-flash-exp",
                    "processed_at": "2024-11-07",
                    "api_status": "active"
                }
            }
        }
    
    async def chat_completion(self, messages: List[Dict]) -> str:
        """
        ì±„íŒ… ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„±
        """
        try:
            # Format messages for Gemini
            conversation_history = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in messages[-10:]  # Last 10 messages
            ])
            
            prompt = f"""
            ë‹¤ìŒ ëŒ€í™”ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”:
            
            {conversation_history}
            
            Assistant:
            """
            
            response = await self.generate_text(prompt)
            return response
        except Exception as e:
            print(f"Chat completion error: {e}")
            return self._get_fallback_response("ëŒ€í™”")
    
    def _extract_key_points(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        # Simple extraction - can be improved
        lines = text.split('\n')
        key_points = [line.strip() for line in lines if len(line.strip()) > 10][:5]
        return key_points if key_points else ["ìš”ì•½ ì •ë³´ ì¶”ì¶œ ì¤‘"]
    
    def _get_fallback_response(self, prompt: str) -> str:
        """API ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ"""
        return f"""ğŸ¤– AI ë¶„ì„ ê²°ê³¼ (Beta Mode)

**ì…ë ¥ ë‚´ìš©**: {prompt[:200]}{'...' if len(prompt) > 200 else ''}

**ë¶„ì„ ìš”ì•½**: 
ì´ëŠ” Gemini APIì˜ í´ë°± ì‘ë‹µì…ë‹ˆë‹¤. ì‹¤ì œ API ì—°ë™ì´ ì™„ë£Œë˜ë©´ ë” ìƒì„¸í•˜ê³  ì •í™•í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

**ê¸°ëŠ¥ ì•ˆë‚´**:
- âœ¨ ì‹¤ì‹œê°„ AI ì‘ë‹µ
- ğŸ“„ ë¬¸ì„œ ìš”ì•½ ë° ë¶„ì„
- ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¸ì‹ ë° ì„¤ëª…
- ğŸ’¬ ë‹¤ì¤‘ ëŒ€í™” ì§€ì›

**ë‹¤ìŒ ë‹¨ê³„**:
- ë” ìì„¸í•œ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”!
- íŒŒì¼ ì—…ë¡œë“œë¥¼ í†µí•´ AI ë¶„ì„ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•´ë³´ì„¸ìš”.

---
ğŸ’¡ Powered by Gemini 2.0 Flash API"""
    
    def _get_fallback_file_analysis(self, file_path: str, file_type: str) -> Dict[str, Any]:
        """íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ ì‹œ í´ë°±"""
        return {
            "file_path": file_path,
            "file_type": file_type,
            "file_size": Path(file_path).stat().st_size if Path(file_path).exists() else 0,
            "analysis": {
                "status": "analyzed",
                "summary": f"íŒŒì¼ '{Path(file_path).name}' ë¶„ì„ ì™„ë£Œ (Beta Mode)",
                "content_type": "file",
                "key_points": [
                    f"íŒŒì¼ í˜•ì‹: {file_type}",
                    "Gemini API í´ë°± ëª¨ë“œ",
                    "ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ"
                ],
                "metadata": {
                    "model": "gemini-2.5-flash-exp-fallback",
                    "processed_at": "2024-11-07",
                    "api_status": "fallback"
                }
            }
        }
    
    def is_configured(self) -> bool:
        """API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        return bool(GEMINI_API_KEYS["main"] and GEMINI_API_KEYS["main"] != "demo-key")
    
    def get_status(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´"""
        return {
            "model": "gemini-2.5-flash-exp",
            "configured": self.is_configured(),
            "api_keys_loaded": {
                "main": bool(GEMINI_API_KEYS["main"]),
                "document": bool(GEMINI_API_KEYS["document"]),
                "audio": bool(GEMINI_API_KEYS["audio"]),
                "image": bool(GEMINI_API_KEYS["image"]),
            },
            "base_url": "https://generativelanguage.googleapis.com/v1beta"
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
gemini_service = GeminiService()
